= Configuration as Code Capability

icon:clock-o[Duration: 15 Minutes] Duration: 15 minutes

Configuration as Code *(CaC)* link:https://www.redhat.com/en/blog/ansible-automation-controller-cac-gitops[link] enables your AAP2 to come up AAP2 resources including:

* Organizations
* Inventories
* Groups
* Hosts
* Credentials
* Projects
* Job Templates 

Or any other resource capable of being installed by the powerful https://console.redhat.com/ansible/automation-hub/repo/published/ansible/controller/docs/[ansible.controller] and https://console.redhat.com/ansible/automation-hub/repo/published/ansible/platform/docs/[ansible.platform] collections. 

You can view all the collections contained within the bundled installer with the `ansible-galaxy` command. 

. Ensure the `ANSIBLE_COLLECTIONS_PATH` env var is set
+

[source,sh,role=execute,subs=attributes+]
----
export ANSIBLE_COLLECTIONS_PATH=/home/devops/aap-2.5-caac/collections
----

. Validate the ANSIBLE_COLLECTIONS_PATH is correctly set via `ansible-galaxy list`
+

[source,sh,role=execute,subs=attributes+]
----
ansible-galaxy collection list
----
+

.Sample Output
[source,texinfo]
----

Collection         Version
------------------ -------
ansible.controller 4.6.1  
ansible.platform   2.5.0   
----

[configure]
== Create a Complete Configuration as Code *(CaC)* Example

In this section, we will create a complete application deployment scenario creating all the resources up to and including a `job_template`.  After the installation is complete we will manually run the `job_template` to both work hands-on with the Containerized AAP2 Console and to check that the (CaC) feature works as expected in creating resources.

You will see the Controller Console is identical to other AAP2 deployment platforms (Red Hat Enterprise Linux, OpenShift, or a Cloud-Based AAP2 such as provided by Azure and AWS). 


. Ensure you are in your config-as-code directory
+

[source,sh,role=execute,subs=attributes+]
----
cd ~/aap-2.5-caac
----

. Add a `controller` sub-directory for a good structure and `cd` into it
+

[TIP]
====
This of course could easily be a Git Repositary which you could easily clone.
====
+

. Create a new file `credentials.yml` and enter the following YAML list
+

[TIP]
====
If you want to add further AAP2 Resources (Inventories, Projects etc) you can refer to the document link:https://galaxy.ansible.com/ui/repo/published/infra/controller_configuration/content/role/organizations/[linked earlier]

Your file names, e.g. `credentials.yml` etc should match the names of the roles in the collections with the postfix `.yml`
   
====
+
image::controller_configuration.png[Lab Topology,align="center",width="100%"]
+

[source,sh,role=execute,subs=attributes+]
----
---
controller_credentials:

  - name: rh1-demo-credential
    credential_type: Machine
    organization: Default
    inputs:
      username: ec2-user
      ssh_key_data: "{{ lookup('file', '/home/devops/.ssh/' + GUID + 'key.pem') }}"
----
+
[NOTE]
====
In the final line, we directly reference a variable `GUID` which is both part of the FQDN of our hosts and also the name of our SSH key (`<GUID>key.pem`). Since our installer has no visibility of the var `GUID` we will have to pass it to the installer at run time ie via `-e GUID={guid}`.

Alternatively, we could hard code it but the above approach is superior and allows easy re-use of a `config-as-code` repo.
====

. Create a new file `organizations.yml` and enter the following YAML list
+

[source,sh,role=execute,subs=attributes+]
---- 
controller_organizations:

  - name: Default
    description: "Default organization for resources"

  - name: Devops
    description: "DevOps and Automation Team"
----

. Create a new file `inventories.yml` and enter the following YAML list
+

[source,sh,role=execute,subs=attributes+]
----
---
controller_inventories:

  - name: rh1-demo-inventory
    organization: Default
    description: {event_name}
----

. Create a new file `hosts.yml` and enter the following YAML list
+

[source,sh,role=execute,subs=attributes+]
----
---
controller_hosts:

  - name: "app-frontend.{{ GUID }}.internal"
    inventory: rh1-demo-inventory
    enabled: true

  - name: "app-backend.{{ GUID }}.internal"
    inventory: rh1-demo-inventory
    enabled: true
----

. Create a new file `groups.yml` and enter the following YAML list
+

[source,sh,role=execute,subs=attributes+]
----
---
controller_groups:

  - name: app_frontends
    description: App frontend
    inventory: rh1-demo-inventory
    hosts:
      - "app-frontend.{{ GUID }}.internal"

  - name: app_backends
    description: App backend
    inventory: rh1-demo-inventory
    hosts:
      - "app-backend.{{ GUID }}.internal"
----

. Create a new file `projects.yml` and enter the following YAML list
+

[source,sh,role=execute,subs=attributes+]
----
---
controller_projects:

  - name: rh1-demo-project
    organization: Default
    scm_branch: main
    scm_clean: 'no'
    scm_delete_on_update: 'no'
    scm_type: git
    scm_update_on_launch: 'no'
    scm_url: https://github.com/rhpds/multi-tier-app-deployer.git
----


. Finally, create a new file `job_templates.yml` and enter the following YAML list
+

[source,sh,role=execute,subs=attributes+]
----
---
controller_templates:

  - name: rh1-demo-job-template
    job_type: run
    inventory: rh1-demo-inventory
    project: rh1-demo-project
    playbook: deploy-app.yml
    credentials:
      - rh1-demo-credential
----

. Check you have the *7* configuration files
+

[source,sh,role=execute,subs=attributes+]
----
ls -1
----
+

.Sample Output
[source,texinfo]
----
credentials.yml
groups.yml
hosts.yml
inventories.yml
job_templates.yml
organizations.yml
projects.yml
----

== Summary

In this module, we added the necessary files and directories to test out the new Postinstall feature available in the TechPreview AAP2 Installer.

In the next module, we will run the Installer and explore the new infrastructure.
